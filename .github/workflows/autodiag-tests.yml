name: AutoDiag v2 Beta - Test Suite

# Trigger on push, pull request, or manual dispatch
on:
  push:
    branches: [ main, develop, feature/* ]
    paths:
      - 'AutoDiag/**'
      - 'shared/**'
      - 'tests/**'
      - '.github/workflows/autodiag-tests.yml'
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

# Cancel in-progress runs when new commit pushed
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================================================
  # JOB 1: UNIT TESTS (FAST - Run on multiple OS/Python versions)
  # ============================================================================
  unit-tests:
    name: Unit Tests (Python ${{ matrix.python-version }}, ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install system dependencies (Ubuntu)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libxcb-xinerama0 \
            libxcb-icccm4 \
            libxcb-image0 \
            libxcb-keysyms1 \
            libxcb-randr0 \
            libxcb-render-util0 \
            libxcb-shape0 \
            libxkbcommon-x11-0 \
            libdbus-1-3 \
            xvfb
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements-dev.txt
      
      - name: Run unit tests
        run: |
          xvfb-run -a pytest tests/ -m unit -v --tb=short --cov=AutoDiag --cov=shared --cov-report=xml --cov-report=term
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unit-tests,python-${{ matrix.python-version }}
          name: unit-py${{ matrix.python-version }}

  # ============================================================================
  # JOB 2: INTEGRATION TESTS (SLOWER - Run on one Python version)
  # ============================================================================
  integration-tests:
    name: Integration Tests (Python 3.11)
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb libxcb-xinerama0 libdbus-1-3
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
      
      - name: Run integration tests
        run: |
          xvfb-run -a pytest tests/ -m integration -v --tb=short --cov=AutoDiag --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: integration-tests

  # ============================================================================
  # JOB 3: CODE QUALITY CHECKS
  # ============================================================================
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt
      
      - name: Run Black (code formatting check)
        continue-on-error: true
        run: |
          black --check AutoDiag/ shared/ tests/ || echo "Black formatting issues found (non-blocking)"
      
      - name: Run isort (import sorting check)
        continue-on-error: true
        run: |
          isort --check-only AutoDiag/ shared/ tests/ || echo "Import sorting issues found (non-blocking)"
      
      - name: Run Flake8 (style guide)
        continue-on-error: true
        run: |
          flake8 AutoDiag/ shared/ tests/ --max-line-length=100 --extend-ignore=E203,W503 || echo "Flake8 issues found (non-blocking)"

  # ============================================================================
  # JOB 4: SECURITY SCAN
  # ============================================================================
  security-scan:
    name: Security Vulnerability Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt
      
      - name: Run Safety (dependency vulnerabilities)
        continue-on-error: true
        run: |
          safety check || echo "Safety check found issues (non-blocking)"
      
      - name: Run Bandit (security linting)
        continue-on-error: true
        run: |
          bandit -r AutoDiag/ shared/ -f json -o bandit-report.json || echo "Bandit found issues (non-blocking)"
      
      - name: Upload Bandit report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bandit-security-report
          path: bandit-report.json

  # ============================================================================
  # JOB 5: MOCK HARDWARE TESTS
  # ============================================================================
  mock-hardware-tests:
    name: Mock Hardware Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb
          pip install -r requirements-dev.txt
      
      - name: Run mock hardware tests
        run: |
          xvfb-run -a pytest tests/ -m "mock and hardware" -v --tb=short

  # ============================================================================
  # JOB 6: PERFORMANCE BENCHMARKS (Optional - Can fail)
  # ============================================================================
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't fail the build if benchmarks fail
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb
          pip install -r requirements-dev.txt
      
      - name: Run performance tests
        run: |
          xvfb-run -a pytest tests/ -m benchmark -v --tb=short
      
      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-benchmarks
          path: .benchmarks/

  # ============================================================================
  # JOB 7: BUILD STATUS SUMMARY
  # ============================================================================
  build-summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, code-quality, security-scan, mock-hardware-tests]
    if: always()
    
    steps:
      - name: Check build status
        run: |
          echo "==================================="
          echo "AutoDiag v2 Beta - Build Summary"
          echo "==================================="
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Mock Hardware: ${{ needs.mock-hardware-tests.result }}"
          echo "==================================="
      
      - name: Fail if critical tests failed
        if: |
          needs.unit-tests.result == 'failure' ||
          needs.integration-tests.result == 'failure'
        run: exit 1
